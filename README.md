# Objectives
**1. Build a generative model that creates X-ray images of hands**

**2. Classify X-ray images of hands generated by different genrative models**

<img src="https://drive.google.com/uc?id=1LubLuuyiJwyDNRd2Wj0vaA0Ek2AtAFxH" width="500"/>

<br>

## 1. Build a generative model that creates X-ray images of hands

### **Task**:
Created generative models, both a VAE or a GANs, trained it, and used it to generate 300 new samples (new images) of X-ray images of hands.

Justified the choice of models and hyperparameters.

### **Dataset**:
8000 samples available in the repository under the folder `real_hands` that can be used to train the VAE and GANs.

### **Deliverables**:
1. `VAE_hands` and `GAN_hands` — folder containting the 300 samples generated with your model. The format is `jpeg`.


2. `GenAI Models.ipynb` — 'clean' notebook containing the code and supporting explanatory text for:
	- Data preparation
	- Design and implementation of networks of choice (VAE or GAN)
	- Implementation of training loops and any other utility functions
	- Executed cells for network training with accompanying loss evolution plots (using livelossplot). Here use the best hyperparameters found. 
	- Generation of 300 samples by using the trained model


3. `Hypertuning.ipynb` — An 'auxiliary' notebook containting any hyperparameter exploration done to decide what are the best hyperparameters to use for the final training. This will include the final training with the choice of hyperparameters in the 'clean' notebook described in point 2.

<br>
<br>

## 2. Classify X-ray images of hands generated by different genrative models

### **Tasks**
#### Task 1
Classified the hand images in the `test_hands` folder. The classifier should classify test hands using the following labels:

- `0`: real hand
- `1`: VAE hand
- `2`: GAN hand

#### Task2
Answer the two questions at the end of this README file. Answer them in the README itself and commit and push your modified README file to your repository.

### **Deliverables**

The final repository should contain the following:

1. `Classification Result.csv`: a comma-separated value file with the name of the hand in the test set, then a comma, and then the prediction for this hand image with the appropriate lable values that the classifier generates.

2. `Classifier.ipynb`: a clean notebook with the classifier workflow, including data preparation, network implementation, final training, final evaluation of the test set, writing of the csv file, and any other step done that is not related to hyperparameter tunning or network design tests (only steps using your best and final classifier model). 

3. `Hypertuning.ipynb`: An 'auxiliary' notebook containting any hyperparameter exploration done to decide what are the best hyperparameters to use for the final network design and training.

### **Task 1 - Classifier**

#### Datasets
You will find the following folders in this repository:
- `real_hands`: contains real hands
- `VAE_hands`: contains hands generated using VAEs from Objective1.
- `GAN_hands`: contains hands generared using GANs from Objective1.
- `test_hands`: contains a mix of real hands, VAE-generated hands, and GAN-generated hands.

Use the four datasets  to design and implement a classifier to label the images in the `test_hands` folder as:

- real hands (label: `0`)
- VAE-generated hands (label: `1`)
- GAN-generated hands (label: `2`)

Implement the network explicitly and train it from randomly initialised weights and any architecture that is useful.

### **Task 2 - Questions**
Modify this README file to include the answers to the questions below.

#### Question 1
If I asked you to do the first coursework again, but now I gave you 5 days and 500 compute units (instead of 100 compute units), what would you do differently to improve your results. In this case, you would be able to use any architecture we have seen in class. Justify your answers well, and do not go over the word limit. You can use bullet points and a maximum of one diagram/figure/table to support your answer.

#### ANSWER 1:

I would still choose GAN for the following reasons:
- GAN produces more realistic images (important for medical use)
- GAN gives better results but it is computationally expensive and unstable, so can benefit from more time and compute units (I nearly ran out of all 100 compute units last time)

Things I would also make a change:
- Use a deeper architecture (including dropout and batch normalisation) for discriminator and generator to capture complex patterns and structures
- Apply data augmentation during training to improve the model's generalization

#### Question 2
Additionally to the newly defined hypotethical assessment in **Question 1**, if i told you that now the images were 512x512 pixels instead of 32x32, and I gave you a choice between these two extra resources:

**a.** as much compute power as you want, but only have the 10000 images provided. <br>
**b.** as many more images in your dataset as you want, but only have the 500 compute units availabe.

Which one would you choose and why? Again justify your answers and use bullet points or tables as you see fit.

#### ANSWER 2:

I would choose option a. in this case for the following reasons:
- The quality of model is more important than the quantity of images given (Can use a deeper architecture without the concern of running out of all compute units).
- High computational resources can accelerate the training process, allowing for more iterations and convergence towards a better-performing model.
- Higher-resolution images (512x512) means more details are kept in the image, so simple structure might not be competent for the generating intricate and realistic images
- While choosing option b. might increase the diversity of output and reduce the risk of overfitting becasue of more inputs given, intricate and detailed images derived from option a. are more crucial for medical images

<br>
